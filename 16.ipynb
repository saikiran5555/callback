{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75dbf4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\91779\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Dimensions of the Wine Quality dataset:\n",
      "Number of rows: 1599\n",
      "Number of columns: 12\n",
      "\n",
      "Shape of features: (1599, 11)\n",
      "Shape of target: (1599,)\n",
      "WARNING:tensorflow:From C:\\Users\\91779\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\91779\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Layer 1:\n",
      "[[ 0.10919911  0.13688299 -0.02881846 -0.19822553  0.07923305  0.00836498\n",
      "  -0.08171816 -0.13359493 -0.18529367 -0.09650981 -0.12741789  0.08480331\n",
      "  -0.25647086  0.25551394 -0.22381724 -0.07953185  0.17949346 -0.01635101\n",
      "  -0.03224498 -0.18257806  0.03498641 -0.02320969 -0.17153478  0.11706108\n",
      "   0.08459926  0.21577933 -0.1930992   0.00880405  0.13537866  0.27923223\n",
      "   0.03685293  0.10172734 -0.15346767 -0.22192238  0.17123476  0.14317313\n",
      "   0.05405667  0.26208255  0.07677928  0.07666221 -0.1130655   0.07356554\n",
      "  -0.04294758  0.01478612 -0.26981732  0.08405375 -0.14852206  0.27150717\n",
      "  -0.17563497  0.21976945  0.17602351  0.03109223  0.14548269 -0.02144256\n",
      "   0.08413044  0.04791206  0.05768028  0.20919573 -0.25849116 -0.21514928\n",
      "   0.03732154  0.23890284 -0.14729474  0.15363654]\n",
      " [-0.23060775 -0.04026164 -0.20875093 -0.05804646 -0.25247616  0.26941267\n",
      "   0.24926916  0.28278777  0.00198993  0.13285673 -0.09496886 -0.02063295\n",
      "   0.21409023 -0.21157935 -0.17185962  0.19008404 -0.09391518  0.0413352\n",
      "  -0.24224459  0.08274701  0.20443717 -0.13471165  0.04144681 -0.00055808\n",
      "  -0.05254829  0.22578898  0.13382676  0.15806457  0.27181807  0.22586057\n",
      "  -0.2437726  -0.18948509 -0.2371192   0.24074015  0.05458388 -0.20157814\n",
      "  -0.09578441  0.1298011   0.12289989  0.26034155  0.03076935 -0.27531132\n",
      "  -0.12212802  0.2432141   0.25753626 -0.04810871  0.00117594 -0.1642396\n",
      "  -0.19484907 -0.2577309   0.17071396  0.17518517  0.09766883 -0.20213974\n",
      "   0.2323443   0.08401102  0.12725213 -0.1646991  -0.00568807  0.06715295\n",
      "  -0.25962245 -0.03245631  0.01369241 -0.28237695]\n",
      " [ 0.19976878  0.07409585  0.04340714  0.0058243  -0.214176    0.03507859\n",
      "   0.12556052  0.19993514 -0.0446845   0.19071782 -0.1399732  -0.1505677\n",
      "   0.00566494  0.24005726 -0.11243869 -0.10133761  0.2068198   0.18902558\n",
      "  -0.03668037 -0.0045917  -0.08851129  0.13084593  0.13348421 -0.05263339\n",
      "   0.1648511   0.11925116  0.07200414 -0.09343916 -0.19567597  0.05465063\n",
      "  -0.10661198  0.02680662 -0.20544553 -0.18681076 -0.19174322  0.07191405\n",
      "  -0.0954316   0.03782621  0.06284514 -0.02928585 -0.20564312 -0.03358537\n",
      "  -0.25760728  0.12669492 -0.06186639  0.06451827 -0.2618432  -0.21651235\n",
      "   0.24340448 -0.09413448  0.21977183 -0.04923622 -0.11752902 -0.00893357\n",
      "   0.00905612 -0.08373703  0.27120498 -0.16221817 -0.07543045 -0.236254\n",
      "   0.09508425  0.04971528  0.25821647 -0.11801699]\n",
      " [ 0.1581459   0.06881198  0.13358435  0.08120963 -0.27879703  0.12684178\n",
      "   0.08952186  0.09803081  0.07951081  0.08685279 -0.1354624  -0.00895962\n",
      "   0.20127171 -0.05802266 -0.2533752  -0.20079845 -0.21457703  0.12443435\n",
      "  -0.25134748 -0.2362499  -0.1993314  -0.13712427  0.25044253  0.12856346\n",
      "   0.22015056  0.24343249 -0.26662314 -0.2807038   0.1555407  -0.03504737\n",
      "   0.23405221  0.12151536 -0.23123556  0.22513089  0.17247146 -0.14064236\n",
      "   0.23366842  0.08441973 -0.05935059 -0.0109528  -0.12021273 -0.12031314\n",
      "  -0.27261925 -0.19657823 -0.20208868  0.21970281 -0.11188148 -0.04776613\n",
      "  -0.26293766 -0.1899705  -0.07094663 -0.18868478 -0.03157049 -0.17811772\n",
      "  -0.04367937  0.04727778  0.10662952  0.05566925 -0.00722262  0.0475972\n",
      "  -0.06407602  0.15408483 -0.06816649 -0.13542707]\n",
      " [ 0.09121549 -0.04744096 -0.07408586  0.04343951 -0.23660156  0.26537457\n",
      "   0.04564869 -0.22317594 -0.03186733 -0.06103733 -0.14687051  0.1479919\n",
      "   0.20245385  0.27616152  0.10768971  0.01881045 -0.10428925 -0.14487754\n",
      "   0.10736138 -0.02237701 -0.0013071   0.12478063 -0.14204581 -0.12519267\n",
      "  -0.01922038  0.13508874 -0.11329937  0.09123167 -0.00458384  0.06137174\n",
      "  -0.13816465  0.21615401  0.04994652 -0.2344015  -0.2724916  -0.21572983\n",
      "  -0.10670052 -0.19004163  0.2439411  -0.01174489 -0.04840785  0.15265724\n",
      "  -0.18092024 -0.02244142  0.20727795 -0.2609072  -0.06948748 -0.01975784\n",
      "   0.01664922  0.10253951  0.25716302 -0.01821202 -0.18465088  0.09286502\n",
      "  -0.24453138  0.181577   -0.02473542  0.18064874 -0.1436691   0.15716776\n",
      "   0.17379966  0.24477193 -0.09201339 -0.00789514]\n",
      " [-0.10078904 -0.18074505  0.00717765 -0.12057991 -0.19485533  0.08199182\n",
      "   0.21801314 -0.21673192 -0.14358939  0.20907003  0.03615168 -0.01561889\n",
      "   0.24309435  0.2710075   0.27487054 -0.08568199 -0.01126555 -0.01597852\n",
      "   0.0540171  -0.00109386  0.04872507  0.16915742  0.14041287 -0.23116529\n",
      "   0.03666756  0.16139343  0.19458073  0.16066185  0.14788735  0.23942605\n",
      "   0.04628229 -0.07536349 -0.16591583  0.25829837 -0.05883288  0.28112528\n",
      "  -0.23834011 -0.13526732 -0.18858854 -0.22054994 -0.2691825  -0.17648187\n",
      "  -0.05620785 -0.09353836 -0.13188674 -0.17817591  0.11149001  0.259137\n",
      "   0.07529795  0.14463031  0.02725828 -0.24071153  0.03901666 -0.0065546\n",
      "  -0.14557408  0.19254273 -0.17821407 -0.11710499 -0.06003344 -0.26297066\n",
      "  -0.10569932 -0.2287495  -0.11328717 -0.18112734]\n",
      " [ 0.05512795  0.18514538 -0.12922825 -0.06291594  0.10103685  0.07345125\n",
      "  -0.12743461  0.12637824  0.07674813  0.04405504  0.0983814   0.09933716\n",
      "   0.12860629  0.00896704 -0.1515772  -0.13628025 -0.2358032  -0.12871405\n",
      "  -0.15086934 -0.0218927  -0.03079471 -0.09612624 -0.07816811 -0.14197454\n",
      "   0.11250195  0.19610706  0.03685713  0.08335373  0.06609672  0.20927435\n",
      "  -0.10141037  0.18658128  0.24917439  0.15327123  0.14501753 -0.10952726\n",
      "  -0.01923469 -0.1414706  -0.24578041 -0.12166966  0.21550688 -0.09968829\n",
      "  -0.13532153 -0.04789406 -0.25185287  0.13032353 -0.2792272  -0.07333909\n",
      "   0.1623111  -0.07035086  0.15492183  0.09832245  0.19322428 -0.13254705\n",
      "  -0.28199205 -0.15557091 -0.17042372  0.15429524  0.07432485 -0.13643819\n",
      "   0.01804599 -0.22204114 -0.05663748  0.15173095]\n",
      " [-0.23259774 -0.07343741  0.02476838  0.17373788 -0.21466523 -0.07241988\n",
      "   0.13525525 -0.06422587 -0.13970697  0.25857463 -0.11426827  0.14434177\n",
      "   0.2094847  -0.11296301 -0.04890889  0.0640966   0.10950863 -0.14919776\n",
      "  -0.08234477  0.2407293  -0.2597132  -0.00746742  0.15947276 -0.08903067\n",
      "  -0.08401567  0.0318608  -0.01252612  0.18927321 -0.19125283 -0.245446\n",
      "   0.1805366  -0.214919    0.17270356 -0.17653562  0.12980065 -0.19402313\n",
      "  -0.01657093  0.14989793 -0.27803427 -0.19164106  0.12773436  0.08044127\n",
      "  -0.05067468  0.24177459 -0.13919061  0.23342416 -0.04010674 -0.18686503\n",
      "  -0.25429583  0.26616082 -0.2812036  -0.06069349 -0.132682   -0.19996159\n",
      "  -0.15639563  0.04927534 -0.01953259 -0.11073279 -0.18008068 -0.22746108\n",
      "  -0.05423908 -0.16113698  0.10376886 -0.01004249]\n",
      " [ 0.02265343  0.12265468  0.06972626 -0.03925119  0.12957    -0.04581828\n",
      "   0.25452045  0.0455898   0.24808326  0.15548006 -0.13014989  0.10257754\n",
      "  -0.22576666 -0.17200029  0.01081523  0.0509032   0.19148737 -0.05268161\n",
      "  -0.11825037  0.09069091  0.2748483  -0.22423548 -0.2776809  -0.12727937\n",
      "   0.18267146 -0.13731033  0.01527584 -0.04320207  0.2625166   0.27264073\n",
      "   0.12061027  0.22691151 -0.03707783 -0.09431669  0.05747083  0.25776634\n",
      "  -0.22380719 -0.16844478 -0.27335712  0.02315089 -0.21054617  0.03422573\n",
      "   0.09634084 -0.18763617 -0.02932563  0.10982263 -0.20645207 -0.11540577\n",
      "   0.04024607 -0.18251556 -0.11678609  0.01448604 -0.01880619  0.23737893\n",
      "  -0.19666031 -0.02751279 -0.01632667  0.15685534 -0.2483053   0.1825059\n",
      "  -0.27689186 -0.15370633 -0.04909785 -0.06943184]\n",
      " [-0.11538628 -0.24287093 -0.01974523  0.17206839 -0.22070998 -0.17584562\n",
      "   0.12242743 -0.2529467   0.14762881  0.1037184   0.01055431 -0.00214666\n",
      "  -0.03687903 -0.23814906 -0.0645892  -0.14066231 -0.24707974  0.02861631\n",
      "  -0.2783477  -0.03339811 -0.08402362  0.13897502  0.25607136  0.04365671\n",
      "   0.21142828 -0.0298619  -0.10816729  0.22017023 -0.15808825 -0.14773354\n",
      "   0.0717988  -0.22607288  0.00132948  0.10370898  0.25593165 -0.1490807\n",
      "   0.04211375  0.04262686 -0.14838322 -0.01176929 -0.21884823  0.05975756\n",
      "   0.15973055 -0.05738762 -0.11251402  0.02676216  0.06932813 -0.20641491\n",
      "  -0.06066954  0.10308337  0.04902217 -0.08383642  0.26674744 -0.0480932\n",
      "   0.26827148  0.25640145 -0.2539996  -0.2481264   0.0567221   0.05622464\n",
      "  -0.25164878 -0.03023055 -0.18573706 -0.13086003]\n",
      " [ 0.17637485 -0.09984326  0.27913406 -0.15462445  0.01770955  0.074857\n",
      "   0.11938801 -0.01538002  0.0044114  -0.09153453  0.07262629 -0.27744833\n",
      "  -0.1039868   0.08785602 -0.02376658  0.07294691  0.20579955 -0.04019502\n",
      "   0.00358921  0.11878717 -0.10309963 -0.03148234 -0.10114448 -0.1965245\n",
      "   0.20051461 -0.04549095  0.2545649   0.14037031  0.26152357  0.22073153\n",
      "  -0.2772684  -0.18669692 -0.04812025  0.05248192 -0.09066719 -0.11746112\n",
      "   0.03342938  0.27266273 -0.22795472  0.00859925  0.00777519 -0.0182848\n",
      "  -0.03221828  0.19411403  0.23928896 -0.05379321 -0.22749358 -0.00547835\n",
      "   0.14213407  0.12989357  0.01246008 -0.04288203  0.07949436 -0.23163868\n",
      "   0.273842    0.07121578 -0.02272746 -0.1294385  -0.11603297  0.16818926\n",
      "  -0.16392252 -0.26351938  0.2632793  -0.12354288]]\n",
      "Shape: (11, 64)\n",
      "\n",
      "Layer 2:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Shape: (64,)\n",
      "\n",
      "Layer 3:\n",
      "[[-2.3674679e-01 -1.7700070e-01 -5.6628406e-02 ...  1.6953313e-01\n",
      "   9.3431890e-02  3.1296313e-02]\n",
      " [ 2.0968509e-01  1.9575107e-01  7.8968108e-02 ... -2.8915882e-02\n",
      "   3.1632781e-03 -1.9010139e-01]\n",
      " [-2.6927590e-02  6.7269564e-02  1.7955399e-01 ... -1.5439737e-01\n",
      "   2.3001432e-04 -1.2945259e-01]\n",
      " ...\n",
      " [-8.7789953e-02  1.6903073e-01 -1.4140493e-01 ...  2.5890470e-03\n",
      "  -2.0790607e-01 -1.8763173e-01]\n",
      " [-1.2355149e-02 -2.0779520e-01  4.7345281e-02 ... -2.9162943e-02\n",
      "  -1.8019205e-01 -6.9946349e-02]\n",
      " [ 1.7468870e-01  2.4046552e-01 -1.0938853e-01 ... -1.3684803e-01\n",
      "  -2.3531538e-01 -5.0132275e-03]]\n",
      "Shape: (64, 32)\n",
      "\n",
      "Layer 4:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Shape: (32,)\n",
      "\n",
      "Layer 5:\n",
      "[[ 0.00414088]\n",
      " [-0.07902107]\n",
      " [ 0.37566465]\n",
      " [ 0.17413121]\n",
      " [-0.30415946]\n",
      " [ 0.32714462]\n",
      " [ 0.10718733]\n",
      " [ 0.3072142 ]\n",
      " [-0.4178953 ]\n",
      " [-0.3642593 ]\n",
      " [-0.29456604]\n",
      " [ 0.35069442]\n",
      " [-0.03539556]\n",
      " [-0.2738108 ]\n",
      " [-0.35308105]\n",
      " [ 0.35250443]\n",
      " [ 0.27314657]\n",
      " [-0.0513556 ]\n",
      " [-0.20770589]\n",
      " [ 0.13679034]\n",
      " [ 0.4136889 ]\n",
      " [ 0.36621267]\n",
      " [-0.2396488 ]\n",
      " [-0.34589344]\n",
      " [-0.3222232 ]\n",
      " [ 0.29521185]\n",
      " [-0.04143888]\n",
      " [ 0.32243532]\n",
      " [ 0.2747423 ]\n",
      " [ 0.2759832 ]\n",
      " [-0.01353011]\n",
      " [-0.22868985]]\n",
      "Shape: (32, 1)\n",
      "\n",
      "Layer 6:\n",
      "[0.]\n",
      "Shape: (1,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Wine Quality dataset\n",
    "wine_data = pd.read_csv('wine.csv')\n",
    "\n",
    "print(\"Dimensions of the Wine Quality dataset:\")\n",
    "print(\"Number of rows:\", wine_data.shape[0])\n",
    "print(\"Number of columns:\", wine_data.shape[1])\n",
    "\n",
    "# Separate features and target variable\n",
    "features = wine_data.drop('quality', axis=1)  # Drop the 'quality' column to get features\n",
    "target = wine_data['quality']  # Select the 'quality' column as the target variable\n",
    "\n",
    "# Display the shapes of features and target\n",
    "print(\"\\nShape of features:\", features.shape)\n",
    "print(\"Shape of target:\", target.shape)\n",
    "\n",
    "# Define the number of neurons in each layer\n",
    "input_neurons = features.shape[1]  # Number of input features\n",
    "hidden_neurons_1 = 64  # Number of neurons in the first hidden layer\n",
    "hidden_neurons_2 = 32  # Number of neurons in the second hidden layer\n",
    "output_neurons = 1  # Number of output neurons (binary classification)\n",
    "\n",
    "# Create a Sequential model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(hidden_neurons_1, activation='relu', input_shape=(input_neurons,)),\n",
    "    tf.keras.layers.Dense(hidden_neurons_2, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_neurons, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Initialize the model by passing some dummy data\n",
    "dummy_input = tf.zeros((1, input_neurons))\n",
    "_ = model(dummy_input)\n",
    "\n",
    "# Get the model's parameters\n",
    "model_params = model.get_weights()\n",
    "\n",
    "# Print the model's parameters\n",
    "for i, layer_params in enumerate(model_params):\n",
    "    print(f\"Layer {i+1}:\")\n",
    "    print(layer_params)\n",
    "    print(\"Shape:\", layer_params.shape)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6236afc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
